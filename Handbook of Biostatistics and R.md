# 生物统计学与R手札

[TOC]

## 目录

* [Introduction](#Introduction)

* [参数检验与非参数检验](#参数检验与非参数检验)

  * [假设检验的步骤](#假设检验的步骤)
  * [单样本参数校验](#总体的单样本参数检验)
  * [类型1和类型2错误](#类型1和类型2错误)
  * [两样本参数检验](#两样本参数检验)
  * [非参数检验](#非参数检验)
  * [多重检验矫正](#多重检验矫正)

* [方差分析](#方差分析)

  * [单因素方差分析](#单因素方差分析)
  * [KW检验](#方差分析非参数检验)
  * [两因素方差分析](#两因素方差分析)
  * [随机效应模型两因素方差分析](#随机效应模型的两因素方差分析)
  * [混合模型两因素方差分析](#混合模型的两因素方差分析)
  * [**小结**](#小结)
  * [缺失值处理](#缺失值处理)

  ​

## Introduction

生物统计学：是统计学在生物学中的应用，是用数理统计的原理和方法来分析解释生命现象的一门科学，是研究生命过程中以样本推断总体的一门科学。

以数理统计原理为基础，应用到生物实验设计和分析领域，这便形成了生物统计学科的框架。所以学习过程是一般在学习概率论与数理统计的同时，对生物领域的实例进行相应分析和解读。

统计分析的流程：

- 设计或形成假设
- 设计相应的实验
- 收集数据
- 分析总结数据
- 形成推断

这与一般的科学研究过程是相同的，实质上生物科学研究的分析过程也就是生物统计分析的实例化。

数据的来源：
$$
Source-of-data 
\begin{cases}
Records    \\
Surveys  \begin{cases} Comprehensive \\ Sample\\\end{cases}  \\
Experiment  \\
\end{cases}
$$
统计学上经常涉及到变量这个概念，它是指**一种体现在不同对象上有不同数值的特征量**，比如人的心率，对象是人，不同的人心率不一样，构成了心率的数值集。

变量有可以分为数值型变量和分类变量，前者通常指能够被测量的数值量，比如身高体重；后者一般指不能被数值化，通过评估生成的变量，比如视力的好坏，病人病情等级等，又可以依据是否有序分为连续型和非连续型变量，比如病人等级从低到高分为几类，这里就包含了变量的顺序(Rank)信息。

总体 *population*： 感兴趣的随机变量的数据总集。 	

样本 *sample*：  总体的抽样。

**注意**：采样尽量为保持一种随机的过程，这是在设计实验时非常需要注意的，不然结果不可靠。

几种采样方式：

- **随机采样**： 通过计算机生成的伪随机数抽取相应的数据；
- **系统采样**： 将数据排序，每隔K个抽取一个数据；
- **Convenience Sampling**： 哪个方便用哪个；
- **分层抽样**： 将总体按相同特征分为至少两类，在类别中分别抽样。
- ......

上述抽样方法详细介绍及优缺点可以参考[百度百科](http://baike.baidu.com/item/%E6%8A%BD%E6%A0%B7%E8%B0%83%E6%9F%A5%E6%B3%95)。

**统计量是样本的描述量；参数是总体的描述量。**

概率相关的基本概念大都不难，理解即可。需要注意的是贝叶斯公式，它在当今各大领域都非常常用，值得深挖。

![beyesi](beyesi.png)

常见概率分布统计书上都有详细介绍，用的时候查询即可。

因为我们常用的数据都很难直接满足正态分布，单为什么用正态分布去理解和计算呢，这里有两个定理概念需要理解：

- **大数定理**就是样本均值在总体数量趋于无穷时依概率收敛于样本均值的数学期望（可不同分布）或者总体的均值（同分布）。
- **中心极限定理**就是一般在同分布的情况下，样本值的和在总体数量趋于无穷时的极限分布近似于正态分布。

**参数估计**

点估计是以抽样得到的样本指标作为总体指标的估计量，并以样本指标的实际值直接作为总体未知参数的估计值的一种推断方法；区间估计则是根据抽样指标和抽样平均误差推断总体指标的可能范围，它既说明推断的准确程度，同时也表明了推断结果的可靠程度。可见，点估计所推断的总体指标是一个确定的数值，而区间估计所推断的总体指标是一个数值域，这个值域受样本指标、极限误差和样本单位数等因素的影响。                        

- **点估计**（Point Estimate）

  [http://wiki.mbalib.com/wiki/点估计](http://wiki.mbalib.com/wiki/%E7%82%B9%E4%BC%B0%E8%AE%A1)

  [http://baike.baidu.com/view/635268.htm](http://baike.baidu.com/view/635268.htm)

  **区间估计**（Interval Estimation）/**置信区间**（Confidence interval）

  [http://wiki.mbalib.com/wiki/置信区间](http://wiki.mbalib.com/wiki/%E7%BD%AE%E4%BF%A1%E5%8C%BA%E9%97%B4)

  [http://baike.baidu.com/view/364109.htm](http://baike.baidu.com/view/364109.htm)

- 在置信度为$1-\alpha$置信度下的

  - 区间估计写为：$\hat{p}-E <p<\hat{p}+E$，点估计写为$p=\hat{p}\pm E$
  - E为误差限，$E=Z_{\alpha/2}\sqrt{\frac{\hat{p}\hat{q}}{n}}$
  - 由上述公式可以推出所需要的样本大小$n=\frac{(Z_{\alpha}/2)^2\hat{p}\hat{q}}{E^2}$
  - 总体方差已知时，估计均值$\mu$使用z分布（u分布），$E=Z_{\alpha/2}\frac{\sigma}{\sqrt{n}}$,$n=[\frac{(Z_{\alpha}/2) \sigma}{E}]^2$
  - 总体方差未知时，估计均值$\mu$使用t分布，$t=\frac{\overline{x}-\mu}{\frac{s}{\sqrt{n}}}$，$E=t_{\alpha}/2\frac{s}{\sqrt{n}}$，$df=n-1$

- 方差估计

  - 卡方分布：$\chi^2=\frac{(n-1)s^2}{\sigma^2}$，$n=sample \quad size,s^2=sample \quad variance, \sigma^2=population \quad variance$
  - 方差的区间估计为$\frac{(n-1)s^2}{\chi_R^2}<\sigma^2<\frac{(n-1)s^2}{\chi_L^2}$

***

## 参数检验与非参数检验

统计中常常提到p值，它的实质是一个小概率事件发生的概率大小值。例如说某件事情的$p<0.05$指的是这件事情发生的概率不超过0.05，因为它发生的概率极小，所以在一般的实验（试验）中，很难碰到这样的事情。因此，当我们碰到这样的事情时，术语说这是一件显著的事情（$p<0.01$为极其显著）。实际实验过程中如果数据噪声服从高斯分布（正态分布），这样的事情应当不会发生（概率很小嘛），那么就应该是其他因素导致的。比如说两组数据进行对比时，如果这两组样本是从同一个总体抽出来的，就应该没什么差异（一般用总体均值$\mu$的假设检验）；如果两组样本经过不同的处理，发现有显著差异（概率很小的事情发生了），说明这两组不同处理的样本映射为不同的总体，我们以此结果来推断两个不同处理的总体它们之间有显著性的差异（所以说实验才是可以重复的，因为每次实验都是对总体的抽样）。

### 假设检验的步骤

一般包括以下四个步骤：

1. 提出假设：一般做两个彼此独立的假设，一个是无效假设或零假设（null hypothesis 很常用），记做$H_0$；另一个是备择假设，称为$H_A$。所谓的无效意指处理效应与总体参数之间没有真实的差异，实验结果中的差异是误差导致的。
2. 确定显著水平：常用$\alpha=0.05  \quad or \quad\alpha=0.01$
3. 计算概率（p值）：有双尾和单尾两种
4. 推断是否接受假设

这方面的知识网上很多，可以参考[百度百科](http://baike.baidu.com/link?url=NY0VUNmmZvwxKiioiUIKaO_qc2tJAlGCa72-nnPg9jv1GIzkmTQomzJYtlYhhUhqIPkJSJWNUU0aNEz1bfpzdx7y0KzR3QyBbpQQWQ9BqceoE63I6-AJpqh7u1brPvU7)或其他资料。

### 总体的单样本参数检验

**总体方差已知时对总体均值检验**

如果总体方差已知，使用z分布（标准正态分布）进行计算

![1-sample1](1-sample1.png)

**总体方差未知时对总体均值进行检验**

如果总体方差未知，使用t分布进行计算

![1-sample2](1-sample2.png)

计算时根据要求，算出z值或者t值，然后与置信度（t分布需要看自由度）下的z（或t）统计量进行对比。观察是在否定区间还是接受区间，从而完成对假设的推断。

当检验是单边时，上述公式的$1-\alpha/2$变成$1-\alpha$

在R中，统计量与分布的计算和图形的绘制可能涉及到的一些函数的使用，可以参考[数值与字符处理函数](http://www.jianshu.com/p/259a1ed171a4)，[基本图形绘制](https://moiedotblog.wordpress.com/2017/04/29/%e5%9f%ba%e6%9c%ac%e7%bb%9f%e8%ae%a1%e5%88%86%e6%9e%90/)。

以下是常用的概率函数

![distribution](distribution.png)

它的使用概率函数形如：`[dpqr] distribution_abbreviation()`

前面一部分是选择计算哪种类型（是概率函数还是分布函数..），后面一部分是指定使用的分布。

比如说`qt()`就是计算t分布的分位数函数，函数具体的参数调用可以使用`help()`进行查询。

在对单样本的总体方差进行检验时，常用卡方分布，两样本则用F分布。

公式分别为：			$\chi^2=\frac{(k-1)s^2}{\sigma^2} \quad df=k-1$

​					$F=\frac{s_1^2}{s_2^2}\quad df_1=n_1-1,df_2=n_2-1$

注意，卡方分布不仅可以用来检验方差同质性，还可以进行适合性和独立性检验，后两者用来判断实际观测值与理论观测值的偏离程度。

当对总体频率进行检验时，如果不满足中心极限定理，则不可以用正态分布进行检验，转而使用二项分布进行检验。

**小结：**

One sample parametric test usually assumes that samples are randomly selected from normal distribution.

- ✤ (1) The mean of a normal distribution with unknown variance (one-sample t test)
- ✤ (2) The mean of a normal distribution with known variance (one-sample z test)
- ✤ (3) The variance of a normal distribution (one-sample 2 test)
- ✤ (4) The parameter p of a binomial distribution (one-sample binomial test)



### 类型1与类型2错误

**两种类型错误及其关系**

```
第一类错误(typeⅠerror)，Ⅰ型错误，拒绝了实际上成立的H0，，即错误地判为有差别，这种弃真的错误称为Ⅰ型错误。其概率大小用即检验水准用α表示。α可取单尾也可取双尾。假设检验时可根据研究目的来确定其大小，一般取0.05，当拒绝H0时则理论上理论100次检验中平均有5次发生这样的错误.。
第二类错误(typeⅡ error)。Ⅱ型错误，接受了实际上不成立的H0 ，也就是错误地判为无差别，这类取伪的错误称为第二类错误。第二类错误的概率用β表示，β的大小很难确切估计。
二者的关系是，当样本例数固定时，α愈小，β愈大；反之，α愈大，β愈小。因而可通过选定α控制β大小。要同时减小α和β，唯有增加样本例数。统计上将1-β称为检验效能或把握度(power of a test)，即两个总体确有差别存在，而以α为检验水准，假设检验能发现它们有差别的能力。实际工作中应权衡两类错误中哪一个重要以选择检验水准的大小。
```

由此引申出几个公式概念，包括灵敏度、特异性、假阳性率等，它们的计算方式如下：

![fr](fr.png)

这些概念常用来计算ROC曲线，该曲线在评判模型的有效性中非常流行。

简单地讲，ROC曲线描绘了灵敏性（真阳性率）随假阳性率（1-特异性）的变化趋势。

AUC则是指ROC曲线下方围成的面积，数值越大，分类器（模型）效果越好。

详细参考：[ROC曲线概念](http://blog.sina.com.cn/s/blog_493b40e10100jps5.html)；[ROC和AUC介绍以及如何计算AUC](http://alexkong.net/2013/06/introduction-to-auc-and-roc/)

**功效**（真阳性率），如果功效过低，那么就算处理不同导致有显著性差异也很难检测出来，所以在进行检验时，我们需要对它进行控制。

**统计检验的功效计算**（分别使用与正态分布、t分布与样本频率检验）

![power1](power1.png)

![power2](power2.png)

效应值： $\frac{|\mu_0 - \mu_1|}{\sigma}$，表示两个总体的平均值差异

功效分析可以帮助在给定置信度的情况下，判断检测到给定效应值所需的样本量。反过来，它也可以帮助你在给定置信度水平情况下，计算在某个样本量内能检测到给定效应值的概率。如果概率低得难以接受，修改或放弃这个实验将是一个明智的选择。

在研究过程时，研究者通常关注四个量：样本大小、显著性水平、功效和效应值。

- 样本大小指实验设计中每种条件中观测的数目。
- 显著性水平（也称为alpha）由I型错误的概率来定义。也可以把它看作发现效应不发生的概率。
- 功效通过1减去II型错误的概率来定义。可以把它看作真实效应发生的概率。
- 效应值指的是在备择或研究假设下效应的值。效应值的表达值依赖于假设检验中使用的统计方法。

四个量紧密相关，给定其中任意三个量，便可以推算第四个量。

我们常常会使用到t分布检验相关的功效分析，这里有一篇值得参考的博文[找出t检验的效应大小，对耍流氓 say no！](http://mp.weixin.qq.com/s?__biz=MzAxMDA4NjU3OA==&mid=2652548856&idx=1&sn=f4d2d21a3bce3f6e34a7d7a99315c004&scene=21)。

功效分析使用到的一些函数和包可以参考[R语言中的功效分析](https://moiedotblog.wordpress.com/2017/04/29/r%e8%af%ad%e8%a8%80%e4%b8%ad%e7%9a%84%e5%8a%9f%e6%95%88%e5%88%86%e6%9e%90/)。

![pwr](pwr.png)



### 两样本参数检验

![two-sample](two-sample.png)

图中$\delta=|\mu_1-\mu_2|$

功效分析和相关检验可以参考上一节。



### 方差分析非参数检验

非参数检验(Nonparametric tests)是统计分析方法的重要组成部分，它与参数检验共同构成统计推断的基本内容。参数检验是在[总体分布](http://baike.baidu.com/item/%E6%80%BB%E4%BD%93%E5%88%86%E5%B8%83)形式已知的情况下，对总体分布的参数如[均值](http://baike.baidu.com/item/%E5%9D%87%E5%80%BC)、[方差](http://baike.baidu.com/item/%E6%96%B9%E5%B7%AE)等进行推断的方法。但是，在数据分析过程中，由于种种原因，人们往往无法对总体分布形态作简单假定，此时参数检验的方法就不再适用了。非参数检验正是一类基于这种考虑，在总体方差未知或知道甚少的情况下，利用样本数据对总体分布形态等进行推断的方法。由于非参数检验方法在推断过程中不涉及有关总体分布的参数，因而得名为“非参数”检验。

也就是说，之前的参数检验，我们在对数据分析之前，需要假定该数据的总体服从某种分布，而这些分布的假定是需要前提条件的，其中最重要的是正态性，而往往我们的数据很难达到这样的要求，甚至对于总体的分布完全一无所知。这个时候我们就可以使用非参数检验。（当然两者之间的优缺点对比还有很多）

一般来说，能用参数检验尽量使用参数检验，因为它的统计效力远高于非参数检验，这也是为什么t检验在文献中非常流行的原因。

非参数检验的种类非常之多，可以参考[百度百科](http://baike.baidu.com/link?url=rw2WQE3crM7Mxlw2sGbvo8A40pLNyAt0CG9smzzEk4iUcxCH5uMoNG2GvTiGl9FKrzwOusid2CfkKw6Oi-KFDIMZqlB_xQeebz2RGsB60fvkg1pVyVLgyjXM1H4fLpb9YfPeH-egOiq_jMFH5eiN-a)，其中常用的是符号检验与符号秩检验。

下表汇出了对总体均值进行检验时，参数和非参数的常用检验对比。

![non-para](non-para.png)

符号检验与秩和检验两种方法相比较，符号检验只考虑样本差数的符号；秩和检验考虑样本差数的符号和样本差数的顺序。

符号检验法是通过两个相关样本的每对数据之差的符号进行检验，从而比较两个样本的显著性。具体地讲，若两个样本差异不显著，正差值与负差值的个数应大致各占一半。

符号检验与参数检验中相关样本显著性[t检验](http://wiki.mbalib.com/wiki/T%E6%A3%80%E9%AA%8C)相对应，当资料不满足参数检验条件时，可采用此法来检验两相关样本的差异显著性。(http://wiki.mbalib.com/wiki/%E7%AC%A6%E5%8F%B7%E6%A3%80%E9%AA%8C)

秩和检验方法最早是由维尔克松提出，叫维尔克松两样本检验法。后来曼—惠特尼将其应用到两[样本容量](http://wiki.mbalib.com/wiki/%E6%A0%B7%E6%9C%AC%E5%AE%B9%E9%87%8F)不等的情况，因而又称为曼—惠特尼U检验。这种方法主要用于比较两个独立样本的差异。(http://wiki.mbalib.com/wiki/%E7%A7%A9%E5%92%8C%E6%A3%80%E9%AA%8C)

**曼-惠特尼U检验**又称“**曼-惠特尼秩和检验**”，是由[H.B.Mann](http://wiki.mbalib.com/w/index.php?title=H.B.Mann&action=edit)和[D.R.Whitney](http://wiki.mbalib.com/w/index.php?title=D.R.Whitney&action=edit)于1947年提出的。它假设两个样本分别来自除了总体均值以外完全相同的两个[总体](http://wiki.mbalib.com/wiki/%E6%80%BB%E4%BD%93)，目的是检验这两个总体的均值是否有显著的差别。

曼-惠特尼秩和检验可以看作是对两均值之差的参数检验方式的[T检验](http://wiki.mbalib.com/wiki/T%E6%A3%80%E9%AA%8C)或相应的大样本正态检验的代用品。由于曼-惠特尼秩和检验明确地考虑了每一个[样本](http://wiki.mbalib.com/wiki/%E6%A0%B7%E6%9C%AC)中各测定值所排的秩，它比[符号检验法](http://wiki.mbalib.com/wiki/%E7%AC%A6%E5%8F%B7%E6%A3%80%E9%AA%8C%E6%B3%95)使用了更多的[信息](http://wiki.mbalib.com/wiki/%E4%BF%A1%E6%81%AF)。(http://wiki.mbalib.com/wiki/%E6%9B%BC-%E6%83%A0%E7%89%B9%E5%B0%BCU%E6%A3%80%E9%AA%8C)

上述文字后链接都有详细介绍和实例。



### 多重检验矫正

数据分析中常碰见多重检验问题(multiple testing).Benjamini于1995年提出一种方法,通过控制FDR(False Discovery Rate)来决定P值的域值。
假设你挑选了R个差异表达的基因，其中有S个是真正有差异表达的，另外有V个其实是没有差异表达的，是假阳性的.实践中希望错误比例Q＝V/R平均而言不能超过某个预先设定的值（比如0.05），在统计学上，这也就等价于控制FDR不能超过5％.
根据Benjamini在他的文章中所证明的定理，控制fdr的步骤实际上非常简单。
设总共有m个候选基因，每个基因对应的p值从小到大排列分别是p(1),p(2),...,p(m),则若想控制fdr不能超过q，则只需找到最大的正整数i，使得 p(i)<= (i*q)/m.然后，挑选对应p(1),p(2),...,p(i)的基因做为差异表达基因，这样就能从统计学上保证fdr不超过q。  

**Bonferroni校正 **　　
如果在同一数据集上同时检验n个独立的假设，那么用于每一假设的统计显著水平，应为仅检验一个假设时的显著水平的1/n。举个例子：如要在同一数据集上检验两个独立的假设，显著水平设为常见的0.05。此时用于检验该两个假设应使用更严格的0.025。即0.05* (1/2)。该方法是由Carlo Emilio Bonferroni发展的，因此称Bonferroni校正。 
这样做的理由是基于这样一个事实：在同一数据集上进行多个假设的检验，每20个假设中就有一个可能纯粹由于概率，而达到0.05的显著水平。

**FDR计算**

![fdr1](fdr1.png)

![fdr_eg](fdr_eg.png)



## 方差分析

### 单因素方差分析

分析流程：

![anova1](anova1.png)

形成列联表

![anova2](anova2.png)

课件8中有一个step-by-step ANOVA按步骤进行单因素方差分析计算。

R中一步搞定可以使用`aov()`与`lm()`函数。[参考](https://moiedotblog.wordpress.com/2017/04/29/%e6%96%b9%e5%b7%ae%e5%88%86%e6%9e%90/)

方差分析主要用于两个及以上不同组实验的分析，探究整体是否存在显著性，如果存在显著性差异，进一步需要配对t检验找出存在差异的组。

R一个非常好用的函数是`TukeyHSD()`。检测方差同质性则使用`bartlett.test()`，`leveneTest()`函数。

单因素方差分析可以用`oneway.test()`函数，设定方差相等时与`aov()`结果相同。

做方差分析时，需要注意使用的模型(https://wenku.baidu.com/view/5516ebcabe23482fb5da4c5b.html)。大致分为三类：固定效应模型，随机效应模型以及混合效应模型。该概念在李春喜《生物统计学》88页有详细介绍。

简单来说，固定模型指各个处理的效应是一个固定的常量，比如不同温度条件下小麦籽粒的发芽实验，处理的水平（温度）是特意选择的，所以得到的结论也仅限于所选定的这几个水平；随机效应指各处理的效应是随机因素，比如不同纬度下桃树对地理条件的适应情况，由于气候、土壤等条件无法人为控制，属于随机因素，就需要随机模型来处理。从而实验所得出的结论可以推广到随机因素的所有水平上。混合模型即为前两者的叠加。

不同的模型在平方和和自由度的计算是相同的，但是假设检验时F值得计算公式是不同的。模型分析的侧重点也不同。对于单因素方差分析来说，固定模型与随机模型无多大区别。

![random_fix1](random_fix1.png)

![random_fix2](random_fix2.png)

### 非参数检验

与t检验类似，方差分析中面对方差不同质或者所处理的数据是有序性而不是数值型时无能为力。因此需要相应的非参数检验来解决这样一类问题。Kruskal-Walls test就是为这个目的开发的。它就像多重样本（multiple-sample）版本的Wilcoxon秩和检验一样。

![kw_test1](kw_test1.png)

![kw_test2](kw_test2.png)

下面截一个实例（对于前面的公式看，比较容易理解）。

![kw_ex1](kw_ex1.png)

![kw_ex2](kw_ex2.png)

在R中，使用函数`kruskal.test()`即可用进行K-W检验。

一但拒绝原假设（有显著性差异），接着使用`pairwise.wilcox.test()`进行两两配对检验，可用指定矫正方法。

### 两因素方差分析

单因素方差分析指一个处理水平，两因素方差分析指两个，多个因素的分析类似。

比如探究某几种药物对某种病（比如癌症）的治疗效果，这个是单因素的，如果我们将病人按性别分为两类，这时就会多出一个性别因素，构成了两因素的方差分析（药物和性别对癌症治疗效果的影响）。

说实话，这个理解不难，手工计算就比较麻烦了。在R中使用函数加上公式可以很容易地表达因变量和自变量的关系，从而完成方差分析。

![aov](aov.png)

下面只截取相应的公式（分随机和固定效应模型）

#### 两因素重复测量方差分析

![twr1](twr1.png)



![twr2](twr2.png)

![twr3](twr3.png)

![twr4](twr4.png)



![twr5](twr5.png)

如果存在显著性差异，在R中使用`TukeyHSD()`函数计算两两之间的显著性。

#### 无重复测量两因素方差分析

![nda1](nda1.png)

这个其实相当于重复测量的简化版了。少了一个假设条件，之前的公式同样适用但是没有了多个测量值计算平均数等一些计算。

### 随机效应模型的两因素方差分析

![nda2](nda2.png)

![nda3](nda3.png)



### 混合模型的两因素方差分析

![nda4](nda4.png)



### 小结

![nda5](nda5.png)

也许方差分析中涉及到的公式略显复杂，计算难度也有很大提升。但是就一个使用者而言，应当理解它的基本内涵和适用范围：它是利用F检验对两个或者两个以上样本的参数检验手段，需要同t检验（可能相对的非参数检验）结合使用；从而完成从多个样本中探寻某些因素对于两个样本之间的影响的过程。它的分析流程如下：![aov2](aov2.png)

### 缺失值处理

这里涉及一些方法和相应的R包，估计需要时查看说明。

![na1](na1.png)

![na2](na2.png)

